{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\dima1\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from gdown) (4.47.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from gdown) (2.24.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from gdown) (4.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2020.6.20)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\dima1\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\n",
      "ERROR: No matching distribution found for zipfile\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# установка необходимых библиотек\n",
    "!pip install gdown\n",
    "!pip install zipfile\n",
    "\n",
    "\n",
    "# создание директории для подготовленных данных\n",
    "!mkdir data_preprocessed\n",
    "\n",
    "\n",
    "# импорт необходимых библиотек\n",
    "import gdown\n",
    "import zipfile\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# скачивание необходимых данных с гугл драйва\n",
    "id = '1IEVhmat6aXEZ3DjMHTx5MtwXACF56iV_'\n",
    "file_path = gdown.download(id=id, quiet=True, output='data_preprocessed/data.zip')\n",
    "\n",
    "\n",
    "# распаковка данных\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('data_preprocessed/')\n",
    "\n",
    "    \n",
    "# удаление ненужных файлов\n",
    "os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек необходимых для подготовки данных\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promo preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TO DO: обработка дат шипмент:\n",
    "    1) сделать так, чтобы не пересекались между собой\n",
    "    2) убрать слишком длинные\n",
    "    3) убрать повторы\n",
    "'''\n",
    "\n",
    "# загрузка данных по промо\n",
    "train_promo = pd.read_excel('data_preprocessed/train_promo.xlsx')\n",
    "test_promo = pd.read_excel('data_preprocessed/test_promo.xlsx')\n",
    "\n",
    "\n",
    "# оставляем данные только по промо для кастомера 1\n",
    "train_promo = train_promo[train_promo.Customer == 1]\n",
    "test_promo = test_promo[test_promo.Customer == 1]\n",
    "\n",
    "## переимнование дфу\n",
    "train_promo.loc[train_promo.DFU == 'Рис длиннозерный 500 гр', 'DFU'] = 'Рис длиннозерный 486 гр'\n",
    "test_promo.loc[test_promo.DFU == 'Рис длиннозерный 500 гр', 'DFU'] = 'Рис длиннозерный 486 гр'\n",
    "\n",
    "## переименование колонок для большего удобства\n",
    "train_promo.rename(columns={'Promo №': 'Promo_', 'Start Date on shelf': 'Start_date_shelf', 'End Date on shelf': 'End_date_shelf',\n",
    "                            'Promo Days on shelf': 'Shelf', 'Shipment days to promo start': 'Ship_days_to_promo', \n",
    "                            'First Date of shipment': 'Start_date', 'End Date of shipment': 'End_date', \n",
    "                            'Shipment duration': 'Ship_duration', 'Discount, %': 'Discount', 'Units SoD': 'SoD_promo'}, inplace=True)\n",
    "\n",
    "test_promo.rename(columns={'Promo №': 'Promo_', 'Start Date on shelf': 'Start_date_shelf', 'End Date on shelf': 'End_date_shelf',\n",
    "                           'Promo Days on shelf': 'Shelf', 'Shipment days to promo start': 'Ship_days_to_promo', \n",
    "                           'First Date of shipment': 'Start_date', 'End Date of shipment': 'End_date', \n",
    "                           'Shipment duration': 'Ship_duration', 'Discount, %': 'Discount', 'Units SoD': 'SoD_promo'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, заполняющая пропущенные периоды, в которые не было продаж\n",
    "def fill_dates(data, fr=None, up=None):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for cust in data.Customer.unique():\n",
    "        for dfu in data[data.Customer == cust].DFU.unique():\n",
    "            temp = data[(data['Customer'] == cust) & (data['DFU'] == dfu)]\n",
    "            \n",
    "            if fr is not None and pd.Timestamp(fr) not in temp.Period.values:\n",
    "                temp = pd.concat((pd.DataFrame([[dfu, cust, pd.Timestamp(fr), 0, 0]], columns=temp.columns), temp))\n",
    "            \n",
    "            if up is not None and pd.Timestamp(up) not in temp.Period.values:\n",
    "                temp = pd.concat((temp, pd.DataFrame([[dfu, cust, pd.Timestamp(up), 0, 0]], columns=temp.columns)))\n",
    "            \n",
    "            temp = temp.set_index('Period').asfreq(freq=pd.DateOffset(days=7)).fillna(value={\"DFU\": dfu, \"Customer\": cust, \"BPV\": 0, \"Total Sell-in\": 0, \"Year\": 0, \"Month\": 0, \"Day\": 0})\n",
    "            result = pd.concat((\n",
    "                result,\n",
    "                temp\n",
    "            ))\n",
    "    return result.reset_index()\n",
    "\n",
    "\n",
    "# функция, зануляющая возвраты по BPV и Total Sell-in, если таковые имеются\n",
    "def fill_returns(data):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for cust in data.Customer.unique():\n",
    "        for dfu in data[data.Customer == cust].DFU.unique():\n",
    "            temp = data[(data.Customer == cust) & (data.DFU == dfu)]\n",
    "            \n",
    "            while (temp['BPV'] < 0).any():\n",
    "                \n",
    "                if temp.iloc[0].BPV < 0:\n",
    "                    temp.loc[temp.Period == temp.iloc[0].Period, 'BPV'] = 0\n",
    "                    \n",
    "                idx_neg = temp[temp['BPV'] < 0].index\n",
    "                \n",
    "                temp.loc[idx_neg - 1, 'BPV'] = temp.loc[idx_neg - 1, 'BPV'] + temp.loc[idx_neg, 'BPV'].values\n",
    "                temp.loc[idx_neg, 'BPV'] = 0\n",
    "            \n",
    "            while (temp['Total Sell-in'] < 0).any():\n",
    "                \n",
    "                if temp.iloc[0]['Total Sell-in'] < 0:\n",
    "                    temp.loc[temp.Period == temp.iloc[0].Period, 'Total Sell-in'] = 0\n",
    "                    \n",
    "                idx_neg = temp[temp['Total Sell-in'] < 0].index\n",
    "                \n",
    "                temp.loc[idx_neg - 1, 'Total Sell-in'] = temp.loc[idx_neg - 1, 'Total Sell-in'] + temp.loc[idx_neg, 'Total Sell-in'].values\n",
    "                temp.loc[idx_neg, 'Total Sell-in'] = 0\n",
    "                \n",
    "            result = pd.concat((result, temp))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# функция соединяющая таблицы promo и sales\n",
    "def join_promo(data, promo):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for dfu in data.DFU.unique():\n",
    "        \n",
    "        temp_sales = data[data.DFU == dfu]\n",
    "        temp_promo = promo[promo.DFU == dfu]\n",
    "        \n",
    "        ### binary\n",
    "        is_promo_shipment = []\n",
    "        promo_shipment_right = []\n",
    "        promo_shipment_left = []\n",
    "        ### numeral\n",
    "        promo_load_shipment = []\n",
    "        promo_week_count = []\n",
    "        \n",
    "        # словарь для подсчета кол-ва использования промо (надо проверить данный признак)\n",
    "        promo_count = dict()\n",
    "        \n",
    "        for idx in temp_sales.index:\n",
    "            \n",
    "            # создаем все необходимые переменные для простановки промо от sales\n",
    "            period_start = temp_sales.loc[idx, 'Period']\n",
    "            period_end = temp_sales.loc[idx, 'Period'] + datetime.timedelta(days=6)\n",
    "            \n",
    "            # условие для отбора промо\n",
    "            condition_shipment_full = (((temp_promo.Start_date < period_start) & (temp_promo.End_date > period_start)) & ((temp_promo.Start_date < period_end) & (temp_promo.End_date > period_end)))\n",
    "            condition_shipment_right = ((~((temp_promo.Start_date < period_start) & (temp_promo.End_date > period_start))) & ((temp_promo.Start_date < period_end) & (temp_promo.End_date > period_end)))\n",
    "            condition_shipment_left = (((temp_promo.Start_date < period_start) & (temp_promo.End_date > period_start)) & (~((temp_promo.Start_date < period_end) & (temp_promo.End_date > period_end))))\n",
    "\n",
    "            # получаем списки промо попадающие под выставленные условия\n",
    "            shipment_promo_full = temp_promo[condition_shipment_full]\n",
    "            shipment_promo_right = temp_promo[condition_shipment_right]\n",
    "            shipment_promo_left = temp_promo[condition_shipment_left]\n",
    "            \n",
    "            # проверим длину всех таблиц\n",
    "            ## shipment\n",
    "            if shipment_promo_full.shape[0] == 0 and shipment_promo_right.shape[0] == 0 and shipment_promo_left.shape[0] == 0:\n",
    "                is_promo_shipment.append(0)\n",
    "                promo_shipment_right.append(0)\n",
    "                promo_shipment_left.append(0)\n",
    "                promo_load_shipment.append(0)\n",
    "                promo_week_count.append(0)\n",
    "                \n",
    "            elif shipment_promo_full.shape[0] != 0:\n",
    "                # получаем полное промо \n",
    "                shipment_promo_full['Length'] = shipment_promo_full['End_date'] - shipment_promo_full['Start_date']\n",
    "                promo_full = shipment_promo_full.sort_values(by='Length').iloc[0]\n",
    "                \n",
    "                # promo count\n",
    "                promo_id = str(promo_full['Start_date'].date()) + '-' + str(promo_full['End_date'].date())\n",
    "                if promo_id not in promo_count:\n",
    "                    promo_count[promo_id] = 1\n",
    "                    promo_week_count.append(promo_count[promo_id])\n",
    "                else:\n",
    "                    promo_count[promo_id] += 1\n",
    "                    promo_week_count.append(promo_count[promo_id])\n",
    "                \n",
    "                # main features\n",
    "                is_promo_shipment.append(1)\n",
    "                promo_shipment_right.append(0)\n",
    "                promo_shipment_left.append(0)\n",
    "                promo_load_shipment.append(7)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                is_promo_shipment.append(1)\n",
    "                promo_load_shipment.append(0)\n",
    "                promo_week_count.append(0)\n",
    "                \n",
    "                if shipment_promo_left.shape[0] != 0:\n",
    "                    # получаем правое промо\n",
    "                    shipment_promo_left['Length'] = shipment_promo_left['End_date'] - shipment_promo_left['Start_date']\n",
    "                    promo_left = shipment_promo_left.sort_values(by='Length').iloc[0]\n",
    "                    \n",
    "                    # promo count\n",
    "                    promo_id = str(promo_left['Start_date'].date()) + '-' + str(promo_left['End_date'].date())\n",
    "                    if promo_id not in promo_count:\n",
    "                        promo_count[promo_id] = 1\n",
    "                        promo_week_count[-1] = promo_count[promo_id]\n",
    "                    else:\n",
    "                        promo_count[promo_id] += 1\n",
    "                        promo_week_count[-1] = promo_count[promo_id]\n",
    "                    \n",
    "                    # main features\n",
    "                    promo_left_start = promo_left['Start_date']\n",
    "                    promo_left_end = promo_left['End_date']\n",
    "                    \n",
    "                    promo_load_shipment[-1] += (promo_left_end - period_start).days\n",
    "                    \n",
    "                    promo_shipment_left.append(1)\n",
    "                \n",
    "                else:\n",
    "                    promo_shipment_left.append(0)\n",
    "                \n",
    "                if shipment_promo_right.shape[0] != 0:\n",
    "                    # получаем правое промо\n",
    "                    shipment_promo_right['Length'] = shipment_promo_right['End_date'] - shipment_promo_right['Start_date']\n",
    "                    promo_right = shipment_promo_right.sort_values(by='Length').iloc[0]\n",
    "                    \n",
    "                    # promo count\n",
    "                    promo_id = str(promo_right['Start_date'].date()) + '-' + str(promo_right['End_date'].date())\n",
    "                    if promo_id not in promo_count:\n",
    "                        promo_count[promo_id] = 1\n",
    "                        promo_week_count[-1] = promo_count[promo_id]\n",
    "                    else:\n",
    "                        promo_count[promo_id] += 1\n",
    "                        promo_week_count[-1] = promo_count[promo_id]\n",
    "                    \n",
    "                    # main features\n",
    "                    promo_right_start = promo_right['Start_date']\n",
    "                    promo_right_end = promo_right['End_date']\n",
    "                    \n",
    "                    promo_load_shipment[-1] += (period_end - promo_right_start).days + 1\n",
    "                    \n",
    "                    promo_shipment_right.append(1)\n",
    "                    \n",
    "                else:\n",
    "                    promo_shipment_right.append(0)\n",
    "                \n",
    "                \n",
    "                if promo_load_shipment[-1] > 7:\n",
    "                    promo_load_shipment[-1] = 7\n",
    "        \n",
    "        # присоединяем размеченные данные\n",
    "        temp_sales['is_promo_shipment'] = is_promo_shipment\n",
    "        temp_sales['promo_shipment_left'] = promo_shipment_left\n",
    "        temp_sales['promo_shipment_right'] = promo_shipment_right\n",
    "        temp_sales['promo_load_shipment'] = promo_load_shipment\n",
    "        \n",
    "        # присоединяем фичу promo count\n",
    "        temp_sales['promo_week_count'] = promo_week_count\n",
    "        \n",
    "        result = pd.concat((result, temp_sales))\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных по продажам\n",
    "train_sales = pd.read_excel('data_preprocessed/train_sales.xlsx')\n",
    "test_sales = pd.read_excel('data_preprocessed/test_sales.xlsx')\n",
    "\n",
    "\n",
    "# заполнение продаж для пропущенных периодов по всем дфу и кастомерам\n",
    "train_sales = fill_dates(train_sales, fr=None, up=str(max(train_sales.Period).date()))\n",
    "train_sales = train_sales.convert_dtypes()\n",
    "\n",
    "test_sales = fill_dates(test_sales, fr=str(min(test_sales.Period).date()), up=str(max(test_sales.Period).date()))\n",
    "test_sales = test_sales.convert_dtypes()\n",
    "\n",
    "\n",
    "# зануление возвратов продаж путем вычитания из прошлых периодов\n",
    "train_sales = fill_returns(train_sales)\n",
    "test_sales = fill_returns(test_sales)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "\n",
    "# разбиение данных на данные для сети и дистрибутора\n",
    "## данные для сети\n",
    "train_sales_net = train_sales[train_sales.Customer == 1]\n",
    "test_sales_net = test_sales[test_sales.Customer == 1]\n",
    "\n",
    "## переимнование дфу\n",
    "train_sales_net.loc[train_sales_net.DFU == 'Рис длиннозерный 500 гр', 'DFU'] = 'Рис длиннозерный 486 гр'\n",
    "\n",
    "## оставляем только те дфу, которые есть и в трейне, и в тесте\n",
    "dfu_list = set(train_sales_net.DFU.unique()).intersection(set(test_sales_net.DFU.unique()))\n",
    "train_sales_net = train_sales_net[train_sales_net.DFU.isin(dfu_list)]\n",
    "test_sales_net = test_sales_net[test_sales_net.DFU.isin(dfu_list)]\n",
    "\n",
    "## объединение таблиц promo и sales\n",
    "train_sales_net = join_promo(train_sales_net, train_promo)\n",
    "test_sales_net = join_promo(test_sales_net, test_promo)\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "\n",
    "# данные для дистрибутора\n",
    "train_sales_dist = train_sales[train_sales.Customer != 1]\n",
    "test_sales_dist = test_sales[test_sales.Customer != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для сети\n",
    "train_sales_net.to_excel('data_preprocessed/train_sales_net.xlsx')\n",
    "test_sales_net.to_excel('data_preprocessed/test_sales_net.xlsx')\n",
    "\n",
    "# Для дистрибутора\n",
    "train_sales_dist.to_excel('data_preprocessed/train_sales_dist.xlsx')\n",
    "test_sales_dist.to_excel('data_preprocessed/test_sales_dist.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
